{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### import library"
      ],
      "metadata": {
        "id": "YxH8q5RD2_1V"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hvBS9nF2cii",
        "outputId": "37787d62-7bae-461a-9540-812df23e00e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (1.0.14)\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.11/dist-packages (2.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from timm) (0.28.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from timm) (0.5.2)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from albumentations) (1.13.1)\n",
            "Requirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.11/dist-packages (from albumentations) (2.10.6)\n",
            "Requirement already satisfied: albucore==0.0.23 in /usr/local/lib/python3.11/dist-packages (from albumentations) (0.0.23)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.11/dist-packages (from albumentations) (4.11.0.86)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.23->albumentations) (3.11.3)\n",
            "Requirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.11/dist-packages (from albucore==0.0.23->albumentations) (6.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.9.2->albumentations) (2.27.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->timm) (4.67.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub->timm) (2025.1.31)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision timm albumentations"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "google drive connect"
      ],
      "metadata": {
        "id": "E9HAE50p3KCa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBfmoPNy2rXl",
        "outputId": "54d74a5d-6e25-466e-c3b8-3c84d28f2cc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### adjust dataset according to training process"
      ],
      "metadata": {
        "id": "U4WtL9iE3clp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8Ht8EIG9ziq",
        "outputId": "08d7fe85-b310-4d27-c0ff-25d26d3b204d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset restructuring complete!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "# Define source and destination paths\n",
        "source_dir = \"/content/drive/MyDrive/intern/dataset\"\n",
        "destination_dir = \"/content/dataset\"\n",
        "\n",
        "# Define train-validation split ratio\n",
        "train_ratio = 0.8  # 80% training, 20% validation\n",
        "\n",
        "# Create train and val directories\n",
        "train_dir = os.path.join(destination_dir, \"train\")\n",
        "val_dir = os.path.join(destination_dir, \"val\")\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(val_dir, exist_ok=True)\n",
        "\n",
        "# Iterate over class folders\n",
        "for class_name in os.listdir(source_dir):\n",
        "    class_path = os.path.join(source_dir, class_name)\n",
        "\n",
        "    if os.path.isdir(class_path):  # Ensure it's a directory\n",
        "        images = os.listdir(class_path)\n",
        "        random.shuffle(images)  # Shuffle for randomness\n",
        "\n",
        "        # Split dataset\n",
        "        split_idx = int(len(images) * train_ratio)\n",
        "        train_images, val_images = images[:split_idx], images[split_idx:]\n",
        "\n",
        "        # Create class directories in train and val\n",
        "        train_class_dir = os.path.join(train_dir, class_name)\n",
        "        val_class_dir = os.path.join(val_dir, class_name)\n",
        "        os.makedirs(train_class_dir, exist_ok=True)\n",
        "        os.makedirs(val_class_dir, exist_ok=True)\n",
        "\n",
        "        # Move images to respective folders\n",
        "        for img in train_images:\n",
        "            shutil.copy(os.path.join(source_dir, class_name, img), os.path.join(train_class_dir, img))\n",
        "\n",
        "        for img in val_images:\n",
        "            shutil.copy(os.path.join(source_dir, class_name, img), os.path.join(val_class_dir, img))\n",
        "\n",
        "print(\"Dataset restructuring complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "import library for Vision Transformer model process"
      ],
      "metadata": {
        "id": "4KewzSs43ovR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zf3AGR7Q3Y5H",
        "outputId": "3b0553bb-cb6d-4d4a-f024-eb3c2b807259"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.4' (you have '2.0.3'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import timm\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import timm\n",
        "import numpy as np\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import cv2\n",
        "import os\n",
        "from PIL import Image\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QT0O6bMfFVbY"
      },
      "outputs": [],
      "source": [
        "#Define transformations for training and validation\n",
        "import albumentations as A\n",
        "train_transforms=A.Compose([\n",
        "    A.Resize(224,224),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.RandomBrightnessContrast(p=0.2),\n",
        "    A.Normalize(mean=(0.485,0.456,0.406),std=(0.229,0.224,0.225)),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "val_transforms=A.Compose([\n",
        "    A.Resize(224,224),\n",
        "    A.Normalize(mean=(0.485,0.456,0.406),std=(0.229,0.224,0.225)),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "# Custom dataset class for Albumentations\n",
        "class AlbumentationsDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self,dataset,transform):\n",
        "    self.dataset=dataset\n",
        "    self.transform=transform\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.dataset)\n",
        "\n",
        "  def __getitem__(self,idx):\n",
        "    img,label=self.dataset[idx]\n",
        "    img=np.array(img)\n",
        "    img=self.transform(image=img)[\"image\"]\n",
        "    return img, label\n",
        "\n",
        "# Define dataset paths\n",
        "train_path=\"/content/dataset/train\"\n",
        "val_path=\"/content/dataset/val\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QCAITb2NI1cv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from torchvision import datasets\n",
        "\n",
        "\n",
        "# Define dataset paths\n",
        "train_path = \"/content/dataset/train\"\n",
        "val_path = \"/content/dataset/val\"\n",
        "\n",
        "# Load datasets directly, assuming the structure is correct\n",
        "train_dataset = datasets.ImageFolder(root=train_path)\n",
        "val_dataset = datasets.ImageFolder(root=val_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "adfpZZlFKCzb"
      },
      "outputs": [],
      "source": [
        "#Apply transformations\n",
        "train_dataset=AlbumentationsDataset(train_dataset,train_transforms)\n",
        "val_dataset=AlbumentationsDataset(val_dataset,val_transforms)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7nMH0Dg9k3k"
      },
      "outputs": [],
      "source": [
        "# Define DataLoaders\n",
        "train_loader=DataLoader(train_dataset,batch_size=32,shuffle=True, num_workers=2)\n",
        "val_loader=DataLoader(val_dataset,batch_size=32,shuffle=False,num_workers=2)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XukGjbMy-CSV",
        "outputId": "6611c826-a3e7-4a0c-b555-32d5052f31d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train samples : 1549,validation samples :395\n"
          ]
        }
      ],
      "source": [
        "print(f\"Train samples : {len(train_dataset)},validation samples :{len(val_dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190,
          "referenced_widgets": [
            "967f488d3ce44260a602184cab35422f",
            "471018a83f3748b385a74393bf4ad78f",
            "c31b34fb2bf144208836ab9b9d8b0787",
            "affe00ae32de44568341314bc640d364",
            "68a64c14c2db47df8c0ac238d3082598",
            "3edddf0b0d494ea5ba22ed0329be3982",
            "b7e86f2fcd7f48d1b19a92f3a42c968a",
            "6aaef4823e7e4371b4719edcb3ef9395",
            "fb5c6ba168ff4ee3bd380b991ce3e529",
            "4db4ae62256140e1ba8fce31ca9faa32",
            "7c12cebf01f547858ff78dd3867074e5"
          ]
        },
        "id": "L_rbdL8M-Sk0",
        "outputId": "a6522ba3-e22a-4bd7-f710-1fe9ea1c4db4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "967f488d3ce44260a602184cab35422f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/346M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device:cuda\n"
          ]
        }
      ],
      "source": [
        "## Load & Fine-tuning vision transformers (ViT)\n",
        "#Load pre-trained vision Transformer\n",
        "\n",
        "model=timm.create_model(\"vit_base_patch16_224\",pretrained=True,num_classes=15)\n",
        "\n",
        "# Freeze backbone layers(except classifier)\n",
        "\n",
        "for param in model.parameters():\n",
        "  param.requires_grad=False # Freeze all layers\n",
        "for param in model.head.parameters():\n",
        "  param.requires_grad=True # Unfreeze classifier layer\n",
        "\n",
        "# Move model to GPU if available\n",
        "device =torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model=model.to(device)\n",
        "\n",
        "# Define loss and optimizer\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer= torch.optim.Adam(model.head.parameters(),lr=1e-4)\n",
        "\n",
        "#Check if GPU is available\n",
        "print(f\"Using device:{device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "start train epochs"
      ],
      "metadata": {
        "id": "AVy9qJ3y4CnI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUro-WSjAEbd",
        "outputId": "2114e1a0-aba3-4ac5-8502-92842630c3a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100 - Train Loss: 15.8697 - Train Acc: 92.51%\n",
            "Validation Accuracy: 88.35% - Validation Loss: 0.3735\n",
            "\n",
            "Epoch 2/100 - Train Loss: 15.6239 - Train Acc: 92.19%\n",
            "Validation Accuracy: 88.10% - Validation Loss: 0.3675\n",
            "\n",
            "Epoch 3/100 - Train Loss: 14.8776 - Train Acc: 92.83%\n",
            "Validation Accuracy: 88.61% - Validation Loss: 0.3603\n",
            "\n",
            "Epoch 4/100 - Train Loss: 13.6789 - Train Acc: 93.67%\n",
            "Validation Accuracy: 88.61% - Validation Loss: 0.3572\n",
            "\n",
            "Epoch 5/100 - Train Loss: 13.2474 - Train Acc: 93.48%\n",
            "Validation Accuracy: 88.86% - Validation Loss: 0.3519\n",
            "\n",
            "Epoch 6/100 - Train Loss: 14.2240 - Train Acc: 92.90%\n",
            "Validation Accuracy: 88.61% - Validation Loss: 0.3479\n",
            "\n",
            "Epoch 7/100 - Train Loss: 13.5857 - Train Acc: 93.35%\n",
            "Validation Accuracy: 89.37% - Validation Loss: 0.3428\n",
            "\n",
            "Epoch 8/100 - Train Loss: 13.4034 - Train Acc: 92.90%\n",
            "Validation Accuracy: 88.86% - Validation Loss: 0.3398\n",
            "\n",
            "Epoch 9/100 - Train Loss: 12.8253 - Train Acc: 93.67%\n",
            "Validation Accuracy: 89.11% - Validation Loss: 0.3366\n",
            "\n",
            "Epoch 10/100 - Train Loss: 12.0346 - Train Acc: 94.13%\n",
            "Validation Accuracy: 88.86% - Validation Loss: 0.3328\n",
            "\n",
            "Epoch 11/100 - Train Loss: 12.9499 - Train Acc: 93.03%\n",
            "Validation Accuracy: 88.86% - Validation Loss: 0.3299\n",
            "\n",
            "Epoch 12/100 - Train Loss: 11.8360 - Train Acc: 94.06%\n",
            "Validation Accuracy: 89.11% - Validation Loss: 0.3278\n",
            "\n",
            "Epoch 13/100 - Train Loss: 12.5403 - Train Acc: 93.16%\n",
            "Validation Accuracy: 88.86% - Validation Loss: 0.3259\n",
            "\n",
            "Epoch 14/100 - Train Loss: 12.6215 - Train Acc: 93.09%\n",
            "Validation Accuracy: 88.86% - Validation Loss: 0.3244\n",
            "\n",
            "Epoch 15/100 - Train Loss: 12.2210 - Train Acc: 93.54%\n",
            "Validation Accuracy: 88.86% - Validation Loss: 0.3233\n",
            "\n",
            "Epoch 16/100 - Train Loss: 11.6514 - Train Acc: 93.61%\n",
            "Validation Accuracy: 88.86% - Validation Loss: 0.3205\n",
            "\n",
            "Epoch 17/100 - Train Loss: 11.3247 - Train Acc: 94.13%\n",
            "Validation Accuracy: 89.11% - Validation Loss: 0.3193\n",
            "\n",
            "Epoch 18/100 - Train Loss: 11.5249 - Train Acc: 93.80%\n",
            "Validation Accuracy: 89.11% - Validation Loss: 0.3162\n",
            "\n",
            "Epoch 19/100 - Train Loss: 10.8355 - Train Acc: 94.58%\n",
            "Validation Accuracy: 89.37% - Validation Loss: 0.3142\n",
            "\n",
            "Epoch 20/100 - Train Loss: 10.9171 - Train Acc: 94.45%\n",
            "Validation Accuracy: 89.62% - Validation Loss: 0.3132\n",
            "\n",
            "Epoch 21/100 - Train Loss: 10.2235 - Train Acc: 95.22%\n",
            "Validation Accuracy: 89.62% - Validation Loss: 0.3111\n",
            "\n",
            "Epoch 22/100 - Train Loss: 10.2431 - Train Acc: 95.03%\n",
            "Validation Accuracy: 89.37% - Validation Loss: 0.3085\n",
            "\n",
            "Epoch 23/100 - Train Loss: 10.3915 - Train Acc: 94.84%\n",
            "Validation Accuracy: 89.62% - Validation Loss: 0.3044\n",
            "\n",
            "Epoch 24/100 - Train Loss: 9.4816 - Train Acc: 95.61%\n",
            "Validation Accuracy: 89.62% - Validation Loss: 0.3032\n",
            "\n",
            "Epoch 25/100 - Train Loss: 10.7065 - Train Acc: 94.71%\n",
            "Validation Accuracy: 89.37% - Validation Loss: 0.3011\n",
            "\n",
            "Epoch 26/100 - Train Loss: 9.8985 - Train Acc: 95.22%\n",
            "Validation Accuracy: 89.37% - Validation Loss: 0.3023\n",
            "\n",
            "Epoch 27/100 - Train Loss: 9.4974 - Train Acc: 95.35%\n",
            "Validation Accuracy: 89.87% - Validation Loss: 0.3023\n",
            "\n",
            "Epoch 28/100 - Train Loss: 9.7739 - Train Acc: 94.96%\n",
            "Validation Accuracy: 89.62% - Validation Loss: 0.3008\n",
            "\n",
            "Epoch 29/100 - Train Loss: 8.9928 - Train Acc: 95.55%\n",
            "Validation Accuracy: 89.37% - Validation Loss: 0.2993\n",
            "\n",
            "Epoch 30/100 - Train Loss: 9.4186 - Train Acc: 95.35%\n",
            "Validation Accuracy: 89.37% - Validation Loss: 0.2982\n",
            "\n",
            "Epoch 31/100 - Train Loss: 9.3672 - Train Acc: 95.16%\n",
            "Validation Accuracy: 89.62% - Validation Loss: 0.3003\n",
            "\n",
            "Epoch 32/100 - Train Loss: 9.0000 - Train Acc: 95.74%\n",
            "Validation Accuracy: 89.87% - Validation Loss: 0.2990\n",
            "\n",
            "Epoch 33/100 - Train Loss: 9.0200 - Train Acc: 95.80%\n",
            "Validation Accuracy: 89.11% - Validation Loss: 0.2972\n",
            "\n",
            "Epoch 34/100 - Train Loss: 8.8456 - Train Acc: 95.55%\n",
            "Validation Accuracy: 89.87% - Validation Loss: 0.2964\n",
            "\n",
            "Epoch 35/100 - Train Loss: 8.3433 - Train Acc: 96.13%\n",
            "Validation Accuracy: 89.37% - Validation Loss: 0.2937\n",
            "\n",
            "Epoch 36/100 - Train Loss: 9.0587 - Train Acc: 95.67%\n",
            "Validation Accuracy: 89.62% - Validation Loss: 0.2928\n",
            "\n",
            "Epoch 37/100 - Train Loss: 8.8064 - Train Acc: 95.87%\n",
            "Validation Accuracy: 90.13% - Validation Loss: 0.2924\n",
            "\n",
            "Epoch 38/100 - Train Loss: 8.6783 - Train Acc: 95.48%\n",
            "Validation Accuracy: 90.13% - Validation Loss: 0.2923\n",
            "\n",
            "Epoch 39/100 - Train Loss: 8.6840 - Train Acc: 95.74%\n",
            "Validation Accuracy: 90.13% - Validation Loss: 0.2904\n",
            "\n",
            "Epoch 40/100 - Train Loss: 8.0937 - Train Acc: 96.26%\n",
            "Validation Accuracy: 89.87% - Validation Loss: 0.2893\n",
            "\n",
            "Epoch 41/100 - Train Loss: 8.0284 - Train Acc: 96.19%\n",
            "Validation Accuracy: 89.62% - Validation Loss: 0.2903\n",
            "\n",
            "Epoch 42/100 - Train Loss: 8.1960 - Train Acc: 96.06%\n",
            "Validation Accuracy: 89.62% - Validation Loss: 0.2903\n",
            "\n",
            "Epoch 43/100 - Train Loss: 8.1217 - Train Acc: 96.19%\n",
            "Validation Accuracy: 90.13% - Validation Loss: 0.2895\n",
            "\n",
            "Epoch 44/100 - Train Loss: 7.6668 - Train Acc: 96.26%\n",
            "Validation Accuracy: 89.62% - Validation Loss: 0.2895\n",
            "\n",
            "Epoch 45/100 - Train Loss: 8.4623 - Train Acc: 95.93%\n",
            "Validation Accuracy: 89.87% - Validation Loss: 0.2910\n",
            "\n",
            "Early stopping triggered after 45 epochs.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=100, patience=5):\n",
        "    \"\"\"\n",
        "    Trains the model for a specified number of epochs with early stopping.\n",
        "\n",
        "    Args:\n",
        "        model: The model to train.\n",
        "        train_loader: DataLoader for the training data.\n",
        "        val_loader: DataLoader for the validation data.\n",
        "        criterion: The loss function.\n",
        "        optimizer: The optimizer to use.\n",
        "        epochs: The number of epochs to train for (default: 100).\n",
        "        patience: The number of epochs to wait before stopping if validation loss doesn't improve (default: 5).\n",
        "    \"\"\"\n",
        "    best_val_loss = np.inf  # Initialize with a very large value\n",
        "    epochs_without_improvement = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            correct += (outputs.argmax(1) == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "        train_acc = 100 * correct / total\n",
        "        print(f\"Epoch {epoch + 1}/{epochs} - Train Loss: {train_loss:.4f} - Train Acc: {train_acc:.2f}%\")\n",
        "\n",
        "        # Validation step\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "                correct += (outputs.argmax(1) == labels).sum().item()\n",
        "                total += labels.size(0)\n",
        "\n",
        "        val_acc = 100 * correct / total\n",
        "        avg_val_loss = val_loss / len(val_loader)\n",
        "        print(f\"Validation Accuracy: {val_acc:.2f}% - Validation Loss: {avg_val_loss:.4f}\\n\")\n",
        "\n",
        "        # Early stopping check\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            epochs_without_improvement = 0\n",
        "        else:\n",
        "            epochs_without_improvement += 1\n",
        "            if epochs_without_improvement >= patience:\n",
        "                print(f\"Early stopping triggered after {epoch + 1} epochs.\")\n",
        "                break  # Exit the training loop\n",
        "\n",
        "train_model(model, train_loader, val_loader, criterion, optimizer, epochs=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "save model in drive for future use"
      ],
      "metadata": {
        "id": "lh6kwoUK4Kfg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXP3B2_Epczi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdaca342-1a14-47e7-d821-f06d7892e6cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved at /content/drive/MyDrive/vit_model.pth\n"
          ]
        }
      ],
      "source": [
        "# Save model to Google Drive (if mounted)\n",
        "model_path = \"/content/drive/MyDrive/vit_model.pth\"\n",
        "torch.save(model.state_dict(), model_path)\n",
        "print(f\"Model saved at {model_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "load model and test sample data"
      ],
      "metadata": {
        "id": "YBopR3NT4ROS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load trained model\n",
        "model.load_state_dict(torch.load(model_path, map_location=device), strict=False)  # Add strict=False\n",
        "model.eval()\n",
        "\n",
        "# Function to predict class of an image\n",
        "def predict_image(image_path, model, class_names):  # Add class_names argument\n",
        "    # Ensure the image file exists\n",
        "    if not os.path.exists(image_path):\n",
        "        raise FileNotFoundError(f\"Image file not found: {image_path}\")\n",
        "\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    image = val_transforms(image=np.array(image))[\"image\"].unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(image)\n",
        "        class_id = torch.argmax(output, dim=1).item()\n",
        "\n",
        "    # Get class name from class ID\n",
        "    class_name = class_names[class_id]  # Get class name\n",
        "    return class_name  # Return class name instead of ID\n",
        "\n",
        "# Get class names from your dataset\n",
        "class_names = train_dataset.dataset.classes\n",
        "\n",
        "# Provide the correct path to your image\n",
        "image_path = \"/content/test_img.jpg\"\n",
        "\n",
        "# Test on the image, but ensure the image file exists first.\n",
        "if os.path.exists(image_path):\n",
        "  predicted_class_name = predict_image(image_path, model, class_names)  # Pass class_names\n",
        "  print(f\"Predicted class for {image_path}: {predicted_class_name}\")\n",
        "else:\n",
        "  print(f\"Error: Image file not found at {image_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVQYTFhK60HZ",
        "outputId": "b5dad9ae-e391-43e1-b5f9-9342779c2812"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-1872ff1409dc>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(model_path, map_location=device), strict=False)  # Add strict=False\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class for /content/test_img.jpg: Tiger\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Weo4E-1B8_Pz"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3edddf0b0d494ea5ba22ed0329be3982": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "471018a83f3748b385a74393bf4ad78f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3edddf0b0d494ea5ba22ed0329be3982",
            "placeholder": "​",
            "style": "IPY_MODEL_b7e86f2fcd7f48d1b19a92f3a42c968a",
            "value": "model.safetensors: 100%"
          }
        },
        "4db4ae62256140e1ba8fce31ca9faa32": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68a64c14c2db47df8c0ac238d3082598": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6aaef4823e7e4371b4719edcb3ef9395": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c12cebf01f547858ff78dd3867074e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "967f488d3ce44260a602184cab35422f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_471018a83f3748b385a74393bf4ad78f",
              "IPY_MODEL_c31b34fb2bf144208836ab9b9d8b0787",
              "IPY_MODEL_affe00ae32de44568341314bc640d364"
            ],
            "layout": "IPY_MODEL_68a64c14c2db47df8c0ac238d3082598"
          }
        },
        "affe00ae32de44568341314bc640d364": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4db4ae62256140e1ba8fce31ca9faa32",
            "placeholder": "​",
            "style": "IPY_MODEL_7c12cebf01f547858ff78dd3867074e5",
            "value": " 346M/346M [00:01&lt;00:00, 240MB/s]"
          }
        },
        "b7e86f2fcd7f48d1b19a92f3a42c968a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c31b34fb2bf144208836ab9b9d8b0787": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6aaef4823e7e4371b4719edcb3ef9395",
            "max": 346284714,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fb5c6ba168ff4ee3bd380b991ce3e529",
            "value": 346284714
          }
        },
        "fb5c6ba168ff4ee3bd380b991ce3e529": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}